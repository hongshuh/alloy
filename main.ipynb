{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow to generate refractory alloy compositions and predict their strength\n",
    "\n",
    "Steps in this notebook:\n",
    "\n",
    "Training the models:\n",
    "\n",
    "1) Train autoencoder to encode compositions and solidus temperatures into a 2D latent space\n",
    "    Training data is Thermo-Calc equilibrium calculations with compositions randomly sampled from this element palette [Cr, Hf, Nb, Mo, Ta, Ti, Re, V, W, Zr]\n",
    "    Thermo-Calc generated solidus temperature (Tsol), liquidus temperature (Tliq), and the fraction of ordered (N(OrdPh) and disordered (NDisordPh) phases at Tsol\n",
    "    \n",
    "2) Cluster the latent space by Tsol into four solidus temperature classes: 1000-1700, 1700-2400, 2400-3100, 3100-3800 K\n",
    "\n",
    "3) Train a random forest model to predict alloy solidus temperature as a function of composition\n",
    "\n",
    "4) Train a random forest regression model to predict alloy yield strength and ultimate tensile strength as a function of composition and temperature.\n",
    "    Training data is from the literature.\n",
    "\n",
    "Note:  There are saved versions of the autoencoder model in the '/alloy-main/model/' folder.  These models do not need to be retrained, see comments in cells below.\n",
    "\n",
    "Using the models:\n",
    "\n",
    "1) Sample points from clusters in the autoencoder latent space, this example draws from the 3100-3800K Tsolidus cluster\n",
    "\n",
    "2) Decode with autoencoder to compositions with a specified range of Tsol\n",
    "\n",
    "3) Predict solidus with random forest model\n",
    "\n",
    "4) Predict yield strength and ultimate tensile strength with random forest model# Machine Learning for Refractory Alloy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set `load_pretrain = False` if you want to train the models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_pretrain_autoencoder = True # Default: True\n",
    "load_pretrain_RF_solidus = False # Default: False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error,accuracy_score,r2_score\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import lr_scheduler\n",
    "from tqdm import tqdm\n",
    "import pickle\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![fig1](./fig/fig1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tc_data\n",
    "tc_data = pd.read_csv('./data/tc_data.csv')\n",
    "\n",
    "# elements input for autoencoder\n",
    "tc_element = tc_data.iloc[:,:10] \n",
    "tc_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the distribution of the Thermo-Calc data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank by average fraction\n",
    "sort = tc_element.mean().sort_values(ascending=False).reset_index()\n",
    "sort_column = sort['index']\n",
    "tc_element = tc_element[sort_column]\n",
    "elements = tc_element.columns.tolist()\n",
    "print(elements)\n",
    "x_index = np.zeros(len(tc_element))\n",
    "# plt.figure(figsize=(8,8))\n",
    "\n",
    "for i in elements:\n",
    "    condition = tc_element[i] > 0.0\n",
    "    plt.scatter(x_index[condition],tc_element[i][condition],alpha=0.01,s = 100,marker='o')\n",
    "    x_index+=1\n",
    "\n",
    "plt.plot(range(len(elements)),sort[0],'ko-',label='Average Concentration')\n",
    "# plt.legend()\n",
    "plt.xticks(range(len(elements)),elements)\n",
    "plt.ylabel('Fraction')\n",
    "plt.xlim(-1,len(elements))\n",
    "plt.ylim(-0.1,1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc_data.Tsol.hist(bins=100)\n",
    "plt.xlabel('Solidus Temperature(K)')\n",
    "plt.ylabel('Count')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Dataloader for Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset object \n",
    "class Alloy_Dataset(Dataset):\n",
    "    def __init__(self, elements, labels):\n",
    "        super().__init__()\n",
    "        assert len(labels) == len(elements)\n",
    "        self.elements = elements\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "      \n",
    "    def __getitem__(self, index):\n",
    "        input = self.elements[index]\n",
    "        target = self.labels[index]\n",
    "        return input , target\n",
    "\n",
    "data = Alloy_Dataset(tc_element.values,tc_data['label']) # classification\n",
    "# data = Alloy_Dataset(tc_element.values,tc_data['Tsol']) # regression\n",
    "\n",
    "# train test split\n",
    "train_ratio = 0.8\n",
    "train_size = int(train_ratio * len(data))\n",
    "test_size = len(data) - train_size\n",
    "train_set, test_set = torch.utils.data.random_split(data, [train_size, test_size], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "# Dataloader\n",
    "train_loader = DataLoader(\n",
    "    train_set, # The dataset\n",
    "    batch_size=128,      # Batch size\n",
    "    shuffle=True,      # Shuffles the dataset at every epoch\n",
    "    pin_memory=True,   # Copy data to CUDA pinned memory                   # so that they can be transferred to the GPU very fast\n",
    "    num_workers=0      # Number of worker processes for loading data.\n",
    "                       # If zero, use the current process (blocks until data are loaded)\n",
    "                       # Otherwise fork/spawn new processes (asynchronous load)\n",
    "                       # Spawning new processes can be problematic on Windows, see:\n",
    "                       # https://pytorch.org/docs/stable/notes/windows.html#usage-multiprocessing\n",
    "                       )\n",
    "test_loader = DataLoader(test_set,batch_size=128,shuffle=False,pin_memory=True,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check cuda \n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# 'cuda: 0' if multiple GPUs\n",
    "print(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture of Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoder Model\n",
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(10,24),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(24,48),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(48,64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64,32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(32,16),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(16,8),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(8,4),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(4,2)\n",
    "            #nn.ReLU(True)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(2,4),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(4,8),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(8,16),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(16,32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(32,64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64,48),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(48,24),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(24,10),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(2,4)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        en_out  = self.encoder(input)\n",
    "        pred   = self.classifier(en_out)\n",
    "        de_out  = self.decoder(en_out)\n",
    "        return en_out,de_out, pred\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up for training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put model into GPU if available\n",
    "model = autoencoder().double().to(device)\n",
    "\n",
    "# parameters set up\n",
    "epochs = 300\n",
    "loss_ratio = 2\n",
    "criterion1 = nn.MSELoss()\n",
    "criterion2 = nn.CrossEntropyLoss()\n",
    "criterion3 = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "scheduler =  lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, threshold=0.001, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08, verbose=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_pretrain_autoencoder:\n",
    "    pass\n",
    "else:\n",
    "    # trainning\n",
    "    training_loss = []\n",
    "    testing_loss = []\n",
    "    pbar = tqdm(range(epochs))\n",
    "    for i in pbar:\n",
    "        epoch_loss = 0.0\n",
    "        for input, target in train_loader:\n",
    "            model.train()\n",
    "            input = input.to(device)\n",
    "            target = target.to(device)\n",
    "            optimizer.zero_grad() \n",
    "\n",
    "            encode_output,decode_output, prediction = model(input)\n",
    "            loss = criterion1(decode_output,input) + 2 * criterion2(prediction,target) # classification\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            pbar.set_postfix_str({'Epoch': i,'Training Loss': loss.item()})\n",
    "        epoch_loss /= len(train_loader)\n",
    "        training_loss.append(epoch_loss)\n",
    "        scheduler.step(epoch_loss)\n",
    "    plt.plot(range(len(training_loss)),training_loss)\n",
    "    plt.title('Loss vs Epochs')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('Loss')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving or Loading Autoencoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_pretrain_autoencoder:\n",
    "    saving_path = './model/my_model.pth'\n",
    "    model = autoencoder().double().to(device)\n",
    "    if torch.cuda.is_available():\n",
    "        model.load_state_dict(torch.load(saving_path),strict=True)\n",
    "    else:\n",
    "        model.load_state_dict(torch.load(saving_path,map_location=torch.device('cpu')),strict=True)\n",
    "else:\n",
    "    saving_path = './model/model.pth'\n",
    "    torch.save(model.state_dict(),saving_path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list = []\n",
    "target_list = []\n",
    "encode_list = []\n",
    "with torch.no_grad():\n",
    "    for input, target in test_loader:\n",
    "        model.eval()\n",
    "        input = input.to(device)\n",
    "        target_list += target.detach().cpu().numpy().tolist()\n",
    "        encode_output,decode_output, prediction = model(input)\n",
    "        encode_list += encode_output.detach().cpu().numpy().tolist()\n",
    "        pred_list += prediction.detach().cpu().numpy().tolist()\n",
    "    pred_list = np.argmax(pred_list,axis=1)\n",
    "    encode_array=np.array(encode_list)\n",
    "print(f'Accuracy of the Model is {accuracy_score(pred_list,target_list).round(5)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "labels = ['1000 - 1700 K', '1700 - 2400 K', '2400 - 3100 K', '3100 - 3800 K']  # Custom labels for the points\n",
    "scatter = ax.scatter(encode_array[:,0],encode_array[:,1], c= target_list,label = labels,s=10,cmap=plt.cm.get_cmap('Dark2',4))\n",
    "# legend1 = ax.legend(*scatter.legend_elements(), loc = 'best',title = 'Classes')\n",
    "plt.xlabel('Latent Vector1')\n",
    "plt.ylabel('Latent Vector2')\n",
    "# plt.legend(loc = 'lower left')\n",
    "#plt.xlim(-3,10.5)\n",
    "#plt.ylim(-1,1)\n",
    "# plt.axes('off')\n",
    "# ax.add_artist(legend1)\n",
    "handles, _ = scatter.legend_elements()\n",
    "legend1 = ax.legend(handles, labels, loc='center right', title='Classes',bbox_to_anchor=(1.4, 0.5))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor for Solidus Temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![fig2](./fig/fig2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_solt = RandomForestRegressor(n_estimators=200,random_state=42)\n",
    "X = tc_element\n",
    "y = tc_data['Tsol']\n",
    "X_train,X_test, y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "if load_pretrain_RF_solidus:\n",
    "    print(f'Loading Model')\n",
    "    with open('./model/RF_solidus.pkl','rb') as f:\n",
    "        rf_solt = pickle.load(f)\n",
    "else:\n",
    "    print('Saving Model')\n",
    "    rf_solt.fit(X_train,y_train)\n",
    "    with open('./model/RF_solidus.pkl','wb') as f:\n",
    "        pickle.dump(rf_solt,f)\n",
    "y_pred = rf_solt.predict(X_test)\n",
    "print(f'R^2 score = {r2_score(y_pred,y_test)}')\n",
    "print(f'MAE = {mean_absolute_error(y_pred,y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = rf_solt.predict(X_train)\n",
    "plt.plot(y_test,y_test,'r')\n",
    "plt.scatter(y_test,y_pred,alpha=0.15,label='test')\n",
    "plt.scatter(y_train,y_pred_train,alpha=0.15,label='train')\n",
    "plt.xlabel('Solidus Temperature by Thermo-Calc')\n",
    "plt.ylabel('Solidus Temperature by Random Forest')\n",
    "plt.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor for Strength "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![fig3](./fig/fig3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data \n",
    "strength_name = 'YS'\n",
    "strength = pd.read_csv('./data/ys_clean.csv')\n",
    "include_tsol = True\n",
    "# Including Solidus temperature if available\n",
    "\n",
    "augment = True # Augmentation\n",
    "ratio = True # Ratio of Tsol and T test\n",
    "if include_tsol == False:\n",
    "    strength.drop(columns=['Solidus temperature'],inplace=True)\n",
    "elif ratio == True:\n",
    "    strength['ratio'] = strength['Test temp']/strength['Solidus temperature']\n",
    "strength"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visulization of data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if include_tsol:\n",
    "    if ratio:\n",
    "        strength_element = strength.iloc[:,3:-1]\n",
    "    else:\n",
    "        strength_element = strength.iloc[:,3:]\n",
    "else:\n",
    "    strength_element = strength.iloc[:,2:]\n",
    "# Rank by average fraction\n",
    "sort = strength_element.mean().sort_values(ascending=False).reset_index()\n",
    "sort_column = sort['index']\n",
    "strength_element = strength_element[sort_column]\n",
    "strength_element\n",
    "elements = strength_element.columns.tolist()\n",
    "print(elements)\n",
    "x_index = np.zeros(len(strength))\n",
    "# plt.figure(figsize=(8,8))\n",
    "\n",
    "for i in elements:\n",
    "    condition = strength_element[i] > 0.0\n",
    "    plt.scatter(x_index[condition],strength_element[i][condition],alpha=0.04,s = 100,marker='o')\n",
    "    x_index+=1\n",
    "\n",
    "plt.plot(range(len(elements)),sort[0],'ko-',label='Average Concentration')\n",
    "plt.legend()\n",
    "plt.xticks(range(len(elements)),elements)\n",
    "plt.ylabel('Fraction')\n",
    "plt.xlim(-1,len(elements))\n",
    "plt.ylim(-0.1,1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strength['Test temp'].hist(bins=100)\n",
    "plt.xlabel('Testing Temperature(K)')\n",
    "plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation\n",
    "Set `Strength = 0` at `Solidus Temperature` into train set. Prevent Strength at above alloy Solidus Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation required solidus temperature\n",
    "if augment == True:\n",
    "       augmented_data = strength.copy()\n",
    "       augmented_data['Test temp'] = augmented_data['Solidus temperature']\n",
    "       if ratio ==True:\n",
    "              augmented_data['ratio'] = augmented_data['Test temp']/augmented_data['Solidus temperature']\n",
    "\n",
    "       augmented_data.drop(columns=[strength_name],inplace=True)\n",
    "# augmented_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = strength.drop(columns=[strength_name])\n",
    "y = strength[strength_name]\n",
    "\n",
    "X_train,X_test, y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "\n",
    "if augment:\n",
    "    X_train = pd.concat([X_train,augmented_data])\n",
    "    y_train = y_train.tolist() + np.zeros([len(augmented_data)]).tolist()\n",
    "    y_train = np.array(y_train)\n",
    "rf = RandomForestRegressor(n_estimators=200,random_state=42)\n",
    "rf.fit(X_train,y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "y_pred_train = rf.predict(X_train)\n",
    "print(f'R^2 value of the model is {rf.score(X_test,y_test)}')\n",
    "print(f'Mean absolut Error(MAE) of the model is {mean_absolute_error(y_pred,y_test)}')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.scatter(y_test,y_pred,label='Test',alpha=0.7)\n",
    "plt.scatter(y_train,y_pred_train,label='Train',alpha=0.7)\n",
    "plt.plot(y_train,y_train,'r',label='Pred = Target')\n",
    "plt.legend()\n",
    "plt.xlabel(f'True Value of {strength_name}[MPa]')\n",
    "plt.ylabel(f'Prediction Value of {strength_name}[MPa]')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate New Composition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![fig4](./fig/fig4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_tsol = tc_data[tc_data['label']==3]\n",
    "high_tsol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc_element = high_tsol.iloc[:,:-5]\n",
    "sort = tc_element.mean().sort_values(ascending=False).reset_index()\n",
    "sort_column = sort['index']\n",
    "tc_element = tc_element[sort_column]\n",
    "elements = tc_element.columns.tolist()\n",
    "print(elements)\n",
    "x_index = np.zeros(len(tc_element))\n",
    "# plt.figure(figsize=(8,8))\n",
    "\n",
    "for i in elements:\n",
    "    condition = tc_element[i] > 0.0\n",
    "    plt.scatter(x_index[condition],tc_element[i][condition],alpha=0.01,s = 100,marker='o')\n",
    "    x_index+=1\n",
    "\n",
    "plt.plot(range(len(elements)),sort[0],'ko-',label='Average Concentration')\n",
    "# plt.legend()\n",
    "plt.xticks(range(len(elements)),elements)\n",
    "plt.ylabel('Fraction')\n",
    "plt.xlim(-1,len(elements))\n",
    "plt.ylim(-0.1,1.1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling and Decoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![fig5](./fig/fig5.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_tsol_elements = high_tsol.iloc[:,:-5]\n",
    "high_tsol_tensor = torch.Tensor(high_tsol_elements.to_numpy()).double().to(device)\n",
    "latent_high_tsol = model.encoder(high_tsol_tensor).detach().cpu().numpy()\n",
    "new_composition_latent = []\n",
    "# Generate sample\n",
    "sample_number = 1000\n",
    "for i in range(sample_number):\n",
    "    a,b = np.random.choice(len(latent_high_tsol),2)\n",
    "    new_x = (latent_high_tsol[a][0]  + latent_high_tsol[b][0])/2 \n",
    "    new_y = (latent_high_tsol[a][1]  + latent_high_tsol[b][1])/2\n",
    "    new_composition_latent.append([new_x,new_y])\n",
    "\n",
    "# Decode to composition\n",
    "new_composition = model.decoder(torch.Tensor(new_composition_latent).double().to(device))\n",
    "new_composition = new_composition.detach().cpu().numpy()\n",
    "\n",
    "# Scaled fraction into sum = 1.0\n",
    "new_composition_df = pd.DataFrame(new_composition)\n",
    "new_composition_df.columns = high_tsol_elements.columns\n",
    "new_composition_df['sum'] = new_composition_df.sum(axis=1)\n",
    "for x in high_tsol_elements:\n",
    "    new_composition_df[x] /= new_composition_df['sum']\n",
    "new_composition_df.drop(columns=['sum'],inplace=True)\n",
    "new_composition_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use RF_solidus to predict the Solidus Temperature for new composition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![fig6](./fig/fig6.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_composition_df['Solidus temperature'] = rf_solt.predict(new_composition_df)\n",
    "# new_composition_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![fig7](./fig/fig7.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_input = pd.concat([X_train.iloc[:1,:],new_composition_df])\n",
    "new_input = new_input.iloc[1:,:]\n",
    "new_input.fillna(0,inplace=True)\n",
    "output_file = new_input.drop(columns=['Test temp'])\n",
    "# Prediction for different Testing Temperature\n",
    "T_test_list = np.arange(300,2500,100)\n",
    "for t in T_test_list:\n",
    "    new_input['Test temp'] = t\n",
    "    if ratio:\n",
    "        new_input['ratio'] = new_input['Test temp']/new_input['Solidus temperature']\n",
    "    pred = rf.predict(new_input)\n",
    "    output_file[f'{strength_name}_{t}K'] = pred\n",
    "    plt.scatter(t*np.ones(len(pred)),pred)\n",
    "plt.xlabel('Testing Temperature(K)')\n",
    "plt.ylabel(f'{strength_name} (MPa)')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving New Alloy Strength Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ratio:    \n",
    "    output_file.drop(columns=['ratio'],inplace=True)\n",
    "output_file.to_csv(f'./output/new_alloy_{strength_name}.csv',index=None)\n",
    "output_file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
